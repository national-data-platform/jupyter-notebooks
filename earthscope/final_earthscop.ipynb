{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e917d9d-06a2-4dd6-b5d0-29e62df674b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;\">\n",
    "    <img src=\"earthscope.png\" alt=\"EarthScope Consortium Logo\" style=\"width: 415px;height: 121px; margin-top: 10px;\">\n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0;\">\n",
    "        <img src=\"https://www.sci.utah.edu/images/news/2023/sci-30-multi.jpg\" alt=\"Scientific Computing and Imaging Institute Logo\" width=\"150\"/>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <h1>NSF National Data Platform (NDP)</h1>\n",
    "    <h2>Streaming Data from EarthScope Consortium</h2>\n",
    "</div>\n",
    "\n",
    "The EarthScope Consortium ([www.earthscope.org](https://www.earthscope.org)) streams three-dimensional Global Navigation Satellite System (GNSS) high rate (1hz) position time series from nearly a thousand EarthScope and related GNSS stations. These high precision ground-motion time series are used to study a range of geophysical phenomena including earthquakes, volcanos, tsunamis, hydrologic loads, and glaciers. EarthScope is dedicated to supporting transformative global geophysical research and education through operation of the National Science Foundation’s (NSF) Geodetic GAGE and Seismic SAGE facilities. As part of the National Data Platform (NDP) EarthScope pilot project, the EarthScope GNSS position time series streams are being stored and made available from Data Collaboratory Kafka servers at the University of Utah. This Jupyter Notebook provides tools for access and plotting of sample real time streams and is the foundation for additional services being developed that will facilitate time series analysis including machine learning. \n",
    "\n",
    "#### Users of EarthScope data agree to follow the [EarthScope streaming data policy](https://www.unavco.org/data/policies_forms/data-policy/data-policy-realtime-streaming-gps/data-policy-realtime-streaming-gps.html).\n",
    "\n",
    "---\n",
    "<div style=\"text-align: right; padding: 5px;\">\n",
    "    <p><strong>Contact:</strong> Scientific and Computing Imaging Institute, University of Utah (<a href=\"mailto:saleem.alharir@utah.edu\">saleem.alharir@utah.edu</a>)</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; align-items: center; justify-content: flex-start; margin-top: 20px; border-top: 1px solid #ccc; padding-top: 20px;\">\n",
    "    <img src=\"https://new.nsf.gov/themes/custom/nsf_theme/components/images/logo/logo-desktop.svg\" alt=\"NSF Logo\" style=\"width: 120px; margin-right: 10px;\">\n",
    "    <p style=\"font-size: 12px;\">The National Data Platform was funded by NSF 2333609 under CI, CISE Research Resources programs. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the funders.</p>\n",
    "</div>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1a719-a8e7-4421-9c39-5784cc253fb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "This step provides an example of retrieving a streaming dataset, specifying the dataset name with an EarthScope “SNCL” code. For example, \"csci_ci_ly__20\". The location of the GNSS station corresponding to the SNCL code is plotted on an interactive map.\n",
    "\n",
    "**SNCL Code Breakdown:**\n",
    "- `csci`: GNSS station 4-character ID.\n",
    "- `ci`: Network code indicating Caltech.\n",
    "- Other sources include `pb` for NOTA/EarthScope, `bk` for U.C. Berkeley, and `pw` for CWU.\n",
    "- `ly_`: Common for all GNSS streams.\n",
    "- Last two integers: Processing Package followed by Solution Type.\n",
    "\n",
    "**Processing Package and Solution Type:**\n",
    "- There can be more than one processing stream from each GNSS station as indicated by the following processing package and solution type codes.\n",
    "- Packages used include the CWU server Fastlane (0), Trimble server PIVOT/RTX (1),RTNet server (2), Septentrio on-board (3), Trimble RTX on board (4),and Network solution combining RTNet's RTK and PPPAR, and Trimble RT data (5).\n",
    "- Solution Types include PPP/AR (0), DIF/RTK (1), PPP/AR COMPLETE (2) and PPP/AR FAST+COMPLETE (3).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3cd3b-9907-46bf-b9cf-4dcb1306608e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ndpearthscope import process_datasets, plot_station_location\n",
    "from IPython.display import display \n",
    "\n",
    "# Define the list of dataset names you wish to process\n",
    "dataset_names = [\"csci_ci_ly__201\"]  # Replace these with actual dataset names\n",
    "\n",
    "# Process the datasets\n",
    "datasets_details = process_datasets(dataset_names)\n",
    "\n",
    "# Initialize an empty list to store file paths\n",
    "file_paths = []\n",
    "# Example: Plotting the location of the first dataset\n",
    "if datasets_details:  # Check if the list is not empty\n",
    "    first_dataset_details = datasets_details[0]\n",
    "    latitude = first_dataset_details['latitude']\n",
    "    longitude = first_dataset_details['longitude']\n",
    "    station_name = first_dataset_details['dataset_name']\n",
    "    bootstrap_server = first_dataset_details['bootstrap_server']\n",
    "    topic = first_dataset_details['topic']\n",
    "    file_path = first_dataset_details['file_path']\n",
    "    # Save the file path for later use\n",
    "    file_paths.append(file_path)   \n",
    "    # Save the file path for later use\n",
    "    file_paths.append(file_path)\n",
    "    # Plot and display the station location in one line\n",
    "    station_map = plot_station_location(latitude, longitude, station_name)\n",
    "    display(station_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a728cf-6e4c-4bd8-9ae6-c5ba78f45a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Anomaly Detection in GPS Data\n",
    "\n",
    "This phase of the analysis involves leveraging a subset of the collected GPS data to identify potential anomalies. Here's what happens:\n",
    "\n",
    "- **Data Subset**: Utilizes the first 10,000 rows from the downloaded 1Hz dataset.\n",
    "- **File Path**: `File_path` should be specified as the path to your dataset, which is assumed to be located in the same directory as this notebook.\n",
    "- **Anomaly Detection**: Implements a One-Class SVM (Support Vector Machine) Anomaly Detection algorithm. This sophisticated technique is designed to detect and highlight outliers within the dataset.\n",
    "- **Visualization**: Outliers identified by the algorithm are distinctly marked in red on the plot, making it easier to spot any anomalies in the GPS data.\n",
    "\n",
    "This approach not only facilitates the early detection of irregularities but also aids in understanding the data's underlying patterns and integrity.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20712fa6-3b6e-450d-a106-df8763eb3912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ndpearthscope import detect_and_visualize_anomalies\n",
    "nrows = 10000\n",
    "nu = 0.01\n",
    "detect_and_visualize_anomalies(file_path,nrows,nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0c8e0-1337-4552-90b1-abce1ba4b44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a3a0d4-d35c-4587-b040-c0b1bed09a31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Real-Time Data Streaming and Visualization\n",
    "\n",
    "This section establishes a connection to the Data Collaboratory Kafka server by creating a Kafka Consumer. It focuses on visualizing geospatial data in real-time, particularly:\n",
    "\n",
    "- **Three components of displacement** are plotted in real-time.\n",
    "- **Time Frame**: The visualization covers the last 60 seconds of data.\n",
    "\n",
    "To control the data flow and visualization, utilize the **Jupyter notebook stop button** to halt the plotting process as needed.\n",
    "\n",
    "This real-time data streaming and visualization provide valuable insights into the dynamic changes occurring in the monitored geophysical phenomena, facilitating immediate analysis and decision-making.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3493e-72d7-4ad8-9bce-4d5ab2c11f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ndpearthscope import consume_and_plot_kafka_data\n",
    "consume_and_plot_kafka_data(topic, bootstrap_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c224ea-caf3-4a94-85a2-105e333fdafc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3D Real-time GPS Data Visualization\n",
    "\n",
    "In this segment, we establish a Kafka Consumer to interface with our streaming data infrastructure. This setup enables:\n",
    "\n",
    "- **3D Visualization**: Leveraging real-time GPS data to render dynamic three-dimensional plots.\n",
    "- **Interactivity**: Users can initiate or halt the data visualization process at any time using the **Jupyter notebook stop button**.\n",
    "\n",
    "This approach allows for an immersive exploration of GPS data, providing an intuitive understanding of spatial dynamics as they unfold in real-time.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d4841e-d357-4265-9674-6dabf0fcf312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ndpearthscope import consume_and_plot_kafka_data_3d\n",
    "consume_and_plot_kafka_data_3d(topic, bootstrap_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35322c1d-8cb8-4daf-9f50-39828d88716e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
