{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef13d0d1",
   "metadata": {},
   "source": [
    "# Streaming Capabilities Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9ebe4f",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates how to test the streaming capabilities of the `StreamingClient`. It includes creating Kafka streams, consuming messages, and deleting streams. Sensitive information like usernames and passwords has been replaced with placeholders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ee382",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb0d25",
   "metadata": {},
   "source": [
    "\n",
    "Ensure you have the required dependencies installed and a valid API URL. The provided credentials should also be correct for the specific streams you want to test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import asyncio\n",
    "import logging\n",
    "from streaming import StreamingClient\n",
    "from pointofpresence import APIClient\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "API_URL = \"http://155.101.6.190:8002\"\n",
    "USERNAME = \"placeholder\"  # Replace with your username\n",
    "PASSWORD = \"placeholder\"  # Replace with your password\n",
    "\n",
    "# Stream configurations\n",
    "streams_to_test = [\n",
    "    {\n",
    "        \"keywords\": \"pinguintest,CSV\",\n",
    "        \"match_all\": True,\n",
    "        \"filter_semantics\": [\n",
    "            \"window_filter(5, mean, fixed acidity > 8.7)\",\n",
    "            \"residual sugar > 1.5\",\n",
    "            \"IF window_filter(9, sum, residual sugar > 20) THEN alert = fixed acidity*100 ELSE fixed acidity = fixed acidity*1000\",\n",
    "            \"IF alert IN ['blue'] THEN residual sugar = fixed acidity*100\"\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"keywords\": \"earthscope_kafka_gnss_observations,kafka\",\n",
    "        \"match_all\": True,\n",
    "        \"filter_semantics\": [],\n",
    "        \"username\": \"<earthscope_username>\",  # Replace with the Earthscope stream username\n",
    "        \"password\": \"<earthscope_password>\"   # Replace with the Earthscope stream password\n",
    "    },\n",
    "    {\n",
    "        \"keywords\": \"pokemon\",\n",
    "        \"match_all\": True,\n",
    "        \"filter_semantics\": [\"name IN ['sturdy', 'damp', 'limber']\", \"IF name = 'sturdy' THEN alert = red\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8366426",
   "metadata": {},
   "source": [
    "## Initialize Clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a9f4af",
   "metadata": {},
   "source": [
    "\n",
    "Here, we initialize the `APIClient` and `StreamingClient` that will handle the streams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API Client\n",
    "client = APIClient(base_url=API_URL, username=USERNAME, password=PASSWORD)\n",
    "\n",
    "# Initialize Streaming Client\n",
    "streaming = StreamingClient(pop_client=client)\n",
    "print(f\"User ID: {streaming.user_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65fa21",
   "metadata": {},
   "source": [
    "## Test Stream Creation, Consumption, and Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3423fe6",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we:\n",
    "1. Create Kafka streams.\n",
    "2. Consume messages from the topics.\n",
    "3. Delete the streams after processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daab97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def test_create_and_consume_multiple_kafka_streams():\n",
    "    for stream_config in streams_to_test:\n",
    "        # Step 1: Create the Kafka stream\n",
    "        result = await streaming.create_kafka_stream(\n",
    "            keywords=stream_config.get(\"keywords\", \"\").split(\",\"),\n",
    "            filter_semantics=stream_config.get(\"filter_semantics\", []),\n",
    "            match_all=stream_config.get(\"match_all\", True),\n",
    "            username=stream_config.get(\"username\", None),\n",
    "            password=stream_config.get(\"password\", None)\n",
    "        )\n",
    "\n",
    "        if \"error\" in result:\n",
    "            print(f\"Error creating stream: {result['error']}\")\n",
    "            continue\n",
    "\n",
    "        # Extract the topic and involved streams\n",
    "        topic = result[\"topic\"]\n",
    "        involved_streams = result[\"involved_streams\"]\n",
    "\n",
    "        print(f\"Stream created: {topic}\")\n",
    "        print(f\"Involved streams: {involved_streams}\")\n",
    "\n",
    "        # Step 2: Consume messages from the Kafka topic\n",
    "        print(\"\\nConsuming messages from the Kafka topic...\")\n",
    "        consumer = streaming.consume_kafka_messages(topic)\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            while True:\n",
    "                if time.time() - start_time > 180:\n",
    "                    print(\"Timeout reached while waiting for messages.\")\n",
    "                    break\n",
    "\n",
    "                if not consumer.dataframe.empty:\n",
    "                    print(\"Dataframe received:\")\n",
    "                    print(consumer.dataframe.head())\n",
    "                    break\n",
    "\n",
    "                await asyncio.sleep(1)\n",
    "        finally:\n",
    "            # Stop the consumer\n",
    "            print(\"\\nStopping the Kafka consumer...\")\n",
    "            consumer.stop()\n",
    "\n",
    "        # Step 3: Delete the created Kafka stream\n",
    "        print(\"\\nDeleting the Kafka stream...\")\n",
    "        try:\n",
    "            response = await streaming.delete_stream(topic)\n",
    "            print(response[\"message\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting stream {topic}: {e}\")\n",
    "\n",
    "        time.sleep(10)  # Wait some seconds to let the consumer clear its data\n",
    "\n",
    "# Run the test\n",
    "await test_create_and_consume_multiple_kafka_streams()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
